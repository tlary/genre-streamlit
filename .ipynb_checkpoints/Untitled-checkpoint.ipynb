{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploying ML Models the easy way - Streamlit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducing Streamlit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the [previous post] I described the process and steps required to deploy a Machine Learning model such that it can be used in production and actually generate value. The app was built using the web framework Flask and the project was deployed using Heroku.\n",
    "\n",
    "As a reminder: to create the App we had to know some HTML and web development basics -  things most Data Scientist neither have nor are really interested in. The App also lacked any kind of styling and looks ... well .. at least it gets the job done. \n",
    "\n",
    "In this post, I'll introduce an alternative to this approach, for which no web development knowledge is needed at all. The package I'm going to use is called [Streamlit](https://www.streamlit.io/) and is especially useful for programmers who quickly want to get their models into production or simply to showcase their work. It comes with pretty and consistent styling and takes care of all the design and front end for you. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from fastai.text.all import *\n",
    "import sentencepiece"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start off by giving our app a title using the `st.title()` function. Streamlit titles and texts are also able to handle emojis in markdown form, we also make use of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.title(\"Classify your (German) lyrics! :tada::microphone::notes:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Streamlit comes with a [variety of widgets](https://share.streamlit.io/daniellewisdl/streamlit-cheat-sheet/app.py) that can be used as user input, for example, text input, slider, or predefined selections. These widgets can furthermore be organized in different sections: on the main page, in a sidebar or in containes, which can hold multiple elements. \n",
    "\n",
    "The only input we need for the genre classification are the song's lyrics. A text area is included on the page in which the lyrics can be pasted. Since lyrics are usually rather long with many line breaks, we organize the text area in a container that can be expanded and collapsed. The container will be collapsed by default when initializing the page. We further add a clickable button reading \"Classify Lyrics\" which will start the classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expander = st.beta_expander(\"Lyrics\")\n",
    "with expander:\n",
    "    lyrics = st.text_area(\"Paste your lyrics here:\", height=100)\n",
    "    clicked = st.button(\"Classify lyrics!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to provide the functionality to the streamlit app. Similar to the [custom made app](https://whichgenreisthis.herokuapp.com/) the prediction of the genre should be displayed together with some genre-related image. To do this, we organize the pictures and the prediction together in a container. When the \"Classify Lyrics\" button is clicked, the lyrics are used as input for the model, the prediction is made, and based on the prediction the corresponding image should be displayed and the prediction under this image. We use the same images as before and store them in a folder called \"static\". The code doing this looks like the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if clicked:\n",
    "    st.spinner(\"Predicting the song's genre...\")\n",
    "with st.beta_container():\n",
    "    # make prediction and edit output format\n",
    "    if clicked:\n",
    "        with st.spinner(\"Predicting the song's genre...\"):\n",
    "            pred = learn_inf.predict(lyrics)[0]\n",
    "            img = images + pred + \".jpg\"\n",
    "            # edit string output\n",
    "            if pred == \"hiphop\":\n",
    "                pred = \"Hip-Hop\"\n",
    "            if pred in [\"pop\", \"schlager\"]:\n",
    "                pred = pred.capitalize()\n",
    "            st.image(img, use_column_width=True)\n",
    "            st.info(\"The song's genre is \" + pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, since we are going to use [Streamlit Sharing](https://blog.streamlit.io/introducing-streamlit-sharing/) to deploy the app, and since it does not yet support Git Lfs files, we have to manually download the file from Dropbox. To avoid repeating the download everytime the app starts, we use Streamlit's built-in caching for this purpose. Loading the model into the app then looks as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@st.cache(allow_output_mutation=True)\n",
    "def load_model(url):\n",
    "    modelLink = url\n",
    "    model = requests.get(modelLink).content\n",
    "    return model\n",
    "modelFile = load_model(\"https://www.dl.dropboxusercontent.com/s/v6ezoyjpibrzjvu/genreModel.pkl?dl=0\")\n",
    "model = BytesIO(modelFile)\n",
    "learn_inf = load_learner(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it all together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now simply copy and paste all the above code snippets in a single app.py file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pickle\n",
    "from fastai.text.all import *\n",
    "import sentencepiece\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "st.title(\"Classify your (German) lyrics! :tada::microphone::notes:\")\n",
    "\n",
    "# download model from Dropbox, cache it and load the model into the app\n",
    "@st.cache(allow_output_mutation=True)\n",
    "def load_model(url):\n",
    "    modelLink = url\n",
    "    model = requests.get(modelLink).content\n",
    "    return model\n",
    "modelFile = load_model(\"https://www.dl.dropboxusercontent.com/s/v6ezoyjpibrzjvu/genreModel.pkl?dl=0\")\n",
    "model = BytesIO(modelFile)\n",
    "learn_inf = load_learner(model)\n",
    "\n",
    "# point to the images\n",
    "images = \"./static/\"\n",
    "\n",
    "expander = st.beta_expander(\"Lyrics\")\n",
    "with expander:\n",
    "    lyrics = st.text_area(\"Paste your lyrics here:\", height=100)\n",
    "    clicked = st.button(\"Classify lyrics!\")\n",
    "\n",
    "if clicked:\n",
    "    st.spinner(\"Predicting the song's genre...\")\n",
    "with st.beta_container():\n",
    "    # make prediction and edit output format\n",
    "    if clicked:\n",
    "        with st.spinner(\"Predicting the song's genre...\"):\n",
    "            pred = learn_inf.predict(lyrics)[0]\n",
    "            img = images + pred + \".jpg\"\n",
    "            # edit string output\n",
    "            if pred == \"hiphop\":\n",
    "                pred = \"Hip-Hop\"\n",
    "            if pred in [\"pop\", \"schlager\"]:\n",
    "                pred = pred.capitalize()\n",
    "            st.image(img, use_column_width=True)\n",
    "            st.info(\"The song's genre is \" + pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's it. The app can be run locally by typing `streamlit run app.py` into the terminal in the app's directory or the virtual environment. \n",
    "\n",
    "To deploy the app, one needs to sign-up for a free [Streamlit Sharing account](https://www.streamlit.io/sharing) and can then easily deploy the app from [GitHub](https://github.com/tlary/genre-streamlit).\n",
    "\n",
    "[![Open in Streamlit](https://static.streamlit.io/badges/streamlit_badge_black_white.svg)](https://share.streamlit.io/tlary/genre-streamlit/main/app.py)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvLyrics",
   "language": "python",
   "name": "venvlyrics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
